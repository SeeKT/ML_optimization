{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 最適化アルゴリズム (1)\n",
    "ここでは，非線形最適化問題を解く代表的なアルゴリズムである最急降下法とニュートン法についてまとめる．[1]を参考にした．\n",
    "\n",
    "[1]: 茨木, [最適化の数学](https://www.kyoritsu-pub.co.jp/kenpon/bookDetail/9784320015654), 共立出版,2011.\n",
    "\n",
    "## 考える問題\n",
    "機械学習では，しばしば以下のような制約なしの最適化問題を解く．\n",
    "\n",
    "$$ \\underset{\\boldsymbol{x}}{\\text{minimize}} \\ \\ f(\\boldsymbol{x}) \\ \\ \\text{subject to} \\ \\ \\boldsymbol{x} \\in S \\subset \\mathbb{R}^N.  \\tag{1}$$\n",
    "\n",
    "ここで，$f: \\mathbb{R^N} \\to \\mathbb{R}$ とし，適当な微分可能性を仮定する．例えば，損失を最小にする重みの学習などがこのような問題で表される．"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 解法\n",
    "点 $\\boldsymbol{x}^{*}$ の1次の最適性必要条件は停留点であること，つまり，\n",
    "\n",
    "$$ \\nabla f(\\boldsymbol{x}^{*}) = 0 \\tag{2}$$\n",
    "\n",
    "である．非線形関数 $f$ に対して， (2) を直接解くのは一般に困難である．\n",
    "\n",
    "$\\rightsquigarrow$ 計算を繰り返すことで $\\boldsymbol{x}^{*}$ に収束する点列 $\\{ \\boldsymbol{x}^k \\}$ を生成し， $\\boldsymbol{x}^{*}$ に十分近くなったと判断されたところで計算を終え，その時点の $\\boldsymbol{x}^k$ を $\\boldsymbol{x}^{*}$ の近似解として出力するのが普通．\n",
    "\n",
    "現在の点 $\\boldsymbol{x}^k$ において，ベクトル $d(\\boldsymbol{x}^k) \\in \\mathbb{R}^N$ が\n",
    "\n",
    "$$ \\nabla f(\\boldsymbol{x}^k)^{\\mathrm{T}} d(\\boldsymbol{x}^k) < 0 \\tag{3}$$\n",
    "\n",
    "を満たすならば， $\\nabla f(\\boldsymbol{x}^k)$ ($f(\\boldsymbol{x}^k)$ からの最急増加方向) と $d(\\boldsymbol{x}^k)$ は鈍角をなす．\n",
    "\n",
    "$\\rightsquigarrow$ $d(\\boldsymbol{x}^k)$ は $f$ の降下方向を示す．\n",
    "\n",
    "よって，降下方向ベクトル $d(\\boldsymbol{x}^k)$ を見つけ，\n",
    "\n",
    "$$ \\boldsymbol{x}^{k + 1} = \\boldsymbol{x}^k + \\alpha_k d(\\boldsymbol{x}^k) \\tag{4}$$\n",
    "\n",
    "という修正を行うという方針をとる．$\\alpha_k$ はステップ幅または**学習率**と呼ばれる実数である．\n",
    "\n",
    "$d(\\boldsymbol{x}^k)$ や $\\alpha_k$ をどのように見つけるかによってアルゴリズムが決まる．"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 最急降下法 (Steepest descent / Gradient descent)\n",
    "$d(\\boldsymbol{x}^k)$ として，勾配ベクトル $\\nabla f(\\boldsymbol{x}^k)$ の反対方向\n",
    "\n",
    "$$ d(\\boldsymbol{x}^k) = - \\nabla f(\\boldsymbol{x}^k) \\tag{5}$$\n",
    "\n",
    "を用いるアルゴリズム．1次の方法である．\n",
    "\n",
    "- $d(\\boldsymbol{x}^k)$ は $\\boldsymbol{x}^k$ から見ると最急降下方向．\n",
    "\n",
    "$f(\\boldsymbol{x})$ の関数形によっては更新則 (5) の方向に進んでも関数値が増加することもある．\n",
    "\n",
    "$\\rightsquigarrow$ 学習率 $\\alpha_k$ を\n",
    "\n",
    "$$ \\min \\{f(\\boldsymbol{x}^k + \\alpha d(\\boldsymbol{x}^k)) \\, | \\, \\alpha > 0\\} \\tag{6}$$\n",
    "\n",
    "を実現する $\\alpha$ が存在すればその値に設定する (直線探索)．\n",
    "\n",
    "最急降下法のアルゴリズムを以下に示す．\n",
    "\n",
    "### Algorithm (Steepest)\n",
    "#### Input\n",
    "- $f$: 目的関数\n",
    "- $\\varepsilon$: 閾値\n",
    "#### Output\n",
    "- $\\boldsymbol{x}^{*}$ の近似解 $\\boldsymbol{x}^k$\n",
    "\n",
    "#### 動作\n",
    "1. (初期化) 初期値 $\\boldsymbol{x}^0$ を定める．$k \\leftarrow 0$.\n",
    "1. (終了判定) $\\|\\boldsymbol{x}^{k + 1} - \\boldsymbol{x}^k  \\| < \\varepsilon$ であれば，$\\boldsymbol{x}^k$ を出力して終了．\n",
    "1. (反復) $d(\\boldsymbol{x}^k) \\leftarrow - \\nabla f(\\boldsymbol{x}^k)$. $\\alpha_k \\leftarrow$ 直線探索の近似解とし，(4) で $\\boldsymbol{x}^{k + 1}$ を求める．$k \\leftarrow k + 1$ として 2. へ戻る．\n",
    "\n",
    "### Remark\n",
    "- $\\nabla f$ を解析的に求めるのが困難な場合には自動微分等を用いる．\n",
    "- 最急降下法は，1次近似で最良の方向へ進む．\n",
    "- $\\alpha_k$ が十分に小さいとき，以下の ODE で表される (修正方程式)．\n",
    "    $$ \\dot{\\boldsymbol{x}} = -\\nabla f(\\boldsymbol{x}) $$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 線形探索\n",
    "線形探索として Armijo のルールを用いる．Armijo のルールは以下のような更新則である．\n",
    "\n",
    "$\\beta, \\gamma \\in (0, \\ 1)$ を選び，\n",
    "\n",
    "$$ f(\\boldsymbol{x}^k + \\beta^{\\ell_k} d(\\boldsymbol{x}^k)) - f(\\boldsymbol{x}^k) \\leq \\gamma \\beta^{\\ell_k} \\nabla f(\\boldsymbol{x}^k)^{\\mathrm{T}} d(\\boldsymbol{x}^k) \\tag{7}$$\n",
    "\n",
    "を満たす最小の非負整数 $\\ell_k$ を求め，$t_k = \\beta^{\\ell_k}$ とし，この $t_k$ を学習率 $\\alpha_k$ とする．"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "########## Packages ##########\n",
    "import autograd.numpy as np\n",
    "from lib.lib import Test_function\n",
    "from lib.plot import Plot_func\n",
    "from lib.optimization_methods import Optimization_methods\n",
    "##############################"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "##### instance of the class #####\n",
    "test = Test_function()\n",
    "pf = Plot_func()\n",
    "om = Optimization_methods(maxiter=250)\n",
    "#################################"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "##### execute steepest descent #####\n",
    "xinit = np.array([2.0, 1.5])\n",
    "sphere_steepest_x, itr_sphere_steepest = om.steepest_descent(\n",
    "    func=test.sphere, xinit=xinit)\n",
    "####################################"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converged. #Iter = 60\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_range = np.linspace(-2.5, 2.5, 51); y_range = np.linspace(-2.5, 2.5, 51)\n",
    "pf.plot_contour(\n",
    "    func=test.sphere, x_range=x_range, y_range=y_range, \n",
    "    x_val=sphere_steepest_x.T[0], y_val=sphere_steepest_x.T[1], \n",
    "    itr=itr_sphere_steepest, func_name=\"sphere\", method_name=\"steepest\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./fig/sphere/contour_sphere_steepest.gif\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "##### execute steepest descent #####\n",
    "xinit = np.array([4.0, 2.5])\n",
    "ackley_steepest_x, itr_ackley_steepest = om.steepest_descent(\n",
    "    func=test.ackley, xinit=xinit)\n",
    "####################################"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converged. #Iter = 20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_range = np.linspace(-5, 5, 51); y_range = np.linspace(-5, 5, 51)\n",
    "pf.plot_contour(\n",
    "    func=test.ackley, x_range=x_range, y_range=y_range, \n",
    "    x_val=ackley_steepest_x.T[0], y_val=ackley_steepest_x.T[1], \n",
    "    itr=itr_ackley_steepest, func_name=\"ackley\", method_name=\"steepest\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./fig/ackley/contour_ackley_steepest.gif\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "##### execute steepest descent #####\n",
    "xinit = np.array([3.0, 1.0])\n",
    "easom_steepest_x, itr_easom_steepest = om.steepest_descent(\n",
    "    func=test.easom, xinit=xinit)\n",
    "####################################"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_range = np.linspace(0, 5, 51); y_range = np.linspace(-5, 5, 51)\n",
    "pf.plot_contour(\n",
    "    func=test.easom, x_range=x_range, y_range=y_range, \n",
    "    x_val=easom_steepest_x.T[0], y_val=easom_steepest_x.T[1], \n",
    "    itr=itr_easom_steepest, func_name=\"easom\", method_name=\"steepest\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./fig/easom/contour_easom_steepest.gif\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ニュートン法\n",
    "$\\alpha = 1$ として $d(\\boldsymbol{x}^k)$ として\n",
    "\n",
    "$$ d(\\boldsymbol{x}^k) = - \\nabla^2 f(\\boldsymbol{x}^k)^{-1} \\nabla f(\\boldsymbol{x}^k) \\tag{8}$$\n",
    "\n",
    "を選ぶ方法．$\\nabla^2 f(\\boldsymbol{x}^k)$ は $f$ の $\\boldsymbol{x} = \\boldsymbol{x}^k$ におけるヘッセ行列．正則性は仮定している．\n",
    "\n",
    "以下，アルゴリズムの形に記述する．\n",
    "\n",
    "### Algorithm (Steepest)\n",
    "#### Input\n",
    "- $f$: 目的関数\n",
    "- $\\varepsilon$: 閾値\n",
    "#### Output\n",
    "- $\\boldsymbol{x}^{*}$ の近似解 $\\boldsymbol{x}^k$\n",
    "\n",
    "#### 動作\n",
    "1. (初期化) 初期値 $\\boldsymbol{x}^0$ を定める．$k \\leftarrow 0$.\n",
    "1. (終了判定) $\\|\\boldsymbol{x}^{k + 1} - \\boldsymbol{x}^k  \\| < \\varepsilon$ であれば，$\\boldsymbol{x}^k$ を出力して終了．\n",
    "1. (反復) $d(\\boldsymbol{x}^k) \\leftarrow - \\nabla^2 f(\\boldsymbol{x}^k)^{-1} \\nabla f(\\boldsymbol{x}^k)$, $\\alpha_k \\leftarrow 1$ とし，(4) で $\\boldsymbol{x}^{k + 1}$ を求める．$k \\leftarrow k + 1$ として 2. へ戻る．\n",
    "\n",
    "#### Remark\n",
    "ニュートン法は2次の最適な方向へ進む．実際，Taylor 展開を考えると\n",
    "\n",
    "$$ f(\\boldsymbol{x}^k + \\boldsymbol{d}) \\approx f(\\boldsymbol{x}^k) + \\nabla f(\\boldsymbol{x}^k)^{\\mathrm{T}} \\boldsymbol{d} + \\frac{1}{2} \\boldsymbol{d}^{\\mathrm{T}} \\nabla^2 f(\\boldsymbol{x}^k) \\boldsymbol{d} \\tag{9}$$\n",
    "\n",
    "を得る．$\\boldsymbol{d}$ を変数ベクトルと見て，この関数の停留点条件を求めると，\n",
    "\n",
    "$$ \\nabla f(\\boldsymbol{x}^k) + \\nabla^2 f(\\boldsymbol{x}^k) \\boldsymbol{d} = 0,$$\n",
    "\n",
    "つまり，(8)を得る．\n",
    "\n",
    "ニュートン法は収束が非常に早いが，高次元になると計算が困難になるので，実用的ではない．"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "##### execute Newton #####\n",
    "xinit = np.array([2.0, 1.5])\n",
    "sphere_newton_x, itr_sphere_newton = om.newton(\n",
    "    func=test.sphere, xinit=xinit)\n",
    "##########################"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converged. #Iter = 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_range = np.linspace(-2.5, 2.5, 51); y_range = np.linspace(-2.5, 2.5, 51)\n",
    "pf.plot_contour(\n",
    "    func=test.sphere, x_range=x_range, y_range=y_range, \n",
    "    x_val=sphere_newton_x.T[0], y_val=sphere_newton_x.T[1], \n",
    "    itr=itr_sphere_newton, func_name=\"sphere\", method_name=\"newton\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./fig/sphere/contour_sphere_newton.gif\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "##### execute Newton #####\n",
    "xinit = np.array([4.0, 2.5])\n",
    "ackley_newton_x, itr_ackley_newton = om.newton(\n",
    "    func=test.ackley, xinit=xinit)\n",
    "##########################"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converged. #Iter = 4\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_range = np.linspace(-5, 5, 51); y_range = np.linspace(-5, 5, 51)\n",
    "pf.plot_contour(\n",
    "    func=test.ackley, x_range=x_range, y_range=y_range, \n",
    "    x_val=ackley_newton_x.T[0], y_val=ackley_newton_x.T[1], \n",
    "    itr=itr_ackley_newton, func_name=\"ackley\", method_name=\"newton\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./fig/ackley/contour_ackley_newton.gif\">"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "##### execute Newton #####\n",
    "xinit = np.array([3.0, 1.0])\n",
    "easom_newton_x, itr_easom_newton = om.newton(\n",
    "    func=test.easom, xinit=xinit)\n",
    "##########################"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converged. #Iter = 22\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_range = np.linspace(0, 5, 51); y_range = np.linspace(-5, 5, 51)\n",
    "pf.plot_contour(\n",
    "    func=test.easom, x_range=x_range, y_range=y_range, \n",
    "    x_val=easom_newton_x.T[0], y_val=easom_newton_x.T[1], \n",
    "    itr=itr_easom_newton, func_name=\"easom\", method_name=\"newton\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"./fig/easom/contour_easom_newton.gif\">"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}